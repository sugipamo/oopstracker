"""
Smart Group Splitter - Intelligent subdivision of large function groups.
"""

import re
import sqlite3
import random
import asyncio
import logging
from typing import List, Dict, Tuple, Any, Optional
from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

from .function_group_clustering import FunctionGroup, ClusterSplitResult
from .ai_analysis_coordinator import get_ai_coordinator
from .llm_prompt_handler import LLMPromptHandler


@dataclass
class SplitStrategy:
    """Predefined split strategies for common function patterns."""
    name: str
    patterns: List[Tuple[str, str]]  # (pattern, label) pairs
    description: str


@dataclass
class SplitRule:
    """A split rule generated by LLM."""
    pattern: str
    reasoning: str
    created_at: datetime
    success_count: int = 0
    failure_count: int = 0


class SplitRuleRepository:
    """Repository for managing split rules in SQLite."""
    
    def __init__(self, db_path: str = "split_rules.db"):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)
        self._init_database()
    
    def _init_database(self):
        """Initialize the database schema."""
        try:
            # Ensure directory exists
            db_dir = Path(self.db_path).parent
            if db_dir != Path('.'):
                db_dir.mkdir(parents=True, exist_ok=True)
            
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS split_rules (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        pattern TEXT NOT NULL,
                        reasoning TEXT NOT NULL,
                        created_at TEXT NOT NULL,
                        success_count INTEGER DEFAULT 0,
                        failure_count INTEGER DEFAULT 0
                    )
                ''')
                conn.commit()
        except sqlite3.Error as e:
            self.logger.error(f"Failed to initialize database: {e}")
            raise RuntimeError(f"Cannot initialize split rules database at {self.db_path}: {e}")
        except Exception as e:
            self.logger.error(f"Unexpected error initializing database: {e}")
            raise
    
    def save_rule(self, rule: SplitRule) -> int:
        """Save a split rule to the database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    INSERT INTO split_rules (pattern, reasoning, created_at, success_count, failure_count)
                    VALUES (?, ?, ?, ?, ?)
                ''', (rule.pattern, rule.reasoning, rule.created_at.isoformat(), 
                      rule.success_count, rule.failure_count))
                conn.commit()
                return cursor.lastrowid
        except sqlite3.Error as e:
            self.logger.error(f"Failed to save rule: {e}")
            raise RuntimeError(f"Cannot save split rule to database: {e}")
        except Exception as e:
            self.logger.error(f"Unexpected error saving rule: {e}")
            raise
    
    def get_all_rules(self) -> List[SplitRule]:
        """Get all split rules from the database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    SELECT pattern, reasoning, created_at, success_count, failure_count
                    FROM split_rules
                    ORDER BY success_count DESC, created_at DESC
                ''')
                rules = []
                for row in cursor.fetchall():
                    try:
                        rules.append(SplitRule(
                            pattern=row[0],
                            reasoning=row[1],
                            created_at=datetime.fromisoformat(row[2]),
                            success_count=row[3],
                            failure_count=row[4]
                        ))
                    except Exception as e:
                        self.logger.warning(f"Skipping invalid rule record: {e}")
                        continue
                return rules
        except sqlite3.Error as e:
            self.logger.error(f"Failed to retrieve rules: {e}")
            raise RuntimeError(f"Cannot retrieve split rules from database: {e}")
        except Exception as e:
            self.logger.error(f"Unexpected error retrieving rules: {e}")
            raise
    
    def update_rule_stats(self, pattern: str, success: bool):
        """Update success/failure statistics for a rule."""
        try:
            field = "success_count" if success else "failure_count"
            with sqlite3.connect(self.db_path) as conn:
                conn.execute(f'''
                    UPDATE split_rules
                    SET {field} = {field} + 1
                    WHERE pattern = ?
                ''', (pattern,))
                conn.commit()
        except sqlite3.Error as e:
            self.logger.error(f"Failed to update rule stats: {e}")
            # çµ±è¨ˆæ›´æ–°ã®å¤±æ•—ã¯è‡´å‘½çš„ã§ã¯ãªã„ãŸã‚ã€ã‚¨ãƒ©ãƒ¼ã‚’ãƒ­ã‚°ã«è¨˜éŒ²ã™ã‚‹ãŒä¾‹å¤–ã¯æŠ•ã’ãªã„
        except Exception as e:
            self.logger.error(f"Unexpected error updating rule stats: {e}")


class SmartGroupSplitter:
    """Intelligent splitter that uses domain knowledge to subdivide large groups."""
    
    # Predefined splitting strategies
    SETTER_STRATEGY = SplitStrategy(
        name="setter_subdivision",
        patterns=[
            (r'^__init__$|^__post_init__$', "Constructor/Initializers"),
            (r'set_config|config_set|configure', "Configuration Setters"),
            (r'set_state|state_set|update_state', "State Management"),
            (r'update_(?!state)', "Update Operations"),
            (r'save_|persist_|store_', "Persistence Operations"),
            (r'write_|dump_|export_', "File Writers"),
            (r'load_|read_|import_', "Data Loaders"),
            (r'assign_|bind_|attach_', "Assignment Operations"),
            (r'init(?:ialize)?_|setup_', "Initialization"),
            (r'register_|add_|append_', "Registration Operations"),
            (r'remove_|delete_|clear_', "Removal Operations"),
            (r'reset_|restore_|revert_', "Reset Operations"),
            (r'enable_|disable_|toggle_', "Toggle Operations"),
            (r'modify_|change_|alter_', "Modification Operations"),
            (r'create_|make_|build_', "Creation Operations"),
            (r'apply_|set_(?!config|state)', "General Setters"),
        ],
        description="Subdivide setter functions by operation type"
    )
    
    GETTER_STRATEGY = SplitStrategy(
        name="getter_subdivision",
        patterns=[
            (r'get_config|config_get|configuration', "Configuration Getters"),
            (r'get_state|state_get|current_state', "State Getters"),
            (r'get_data|fetch_data|retrieve_data', "Data Retrievers"),
            (r'get_.*_list|list_|all_', "Collection Getters"),
            (r'is_|has_|can_|should_', "Boolean Getters"),
            (r'find_|search_|locate_', "Search Operations"),
            (r'calculate_|compute_|derive_', "Computed Properties"),
            (r'__get|property|cached_property', "Property Getters"),
            (r'get_', "General Getters"),
        ],
        description="Subdivide getter functions by return type and purpose"
    )
    
    BUSINESS_LOGIC_STRATEGY = SplitStrategy(
        name="business_logic_subdivision",
        patterns=[
            (r'process_|handle_', "Processing Logic"),
            (r'analyze_|inspect_|examine_', "Analysis Logic"),
            (r'calculate_|compute_', "Calculation Logic"),
            (r'validate_|verify_|check_', "Validation Logic"),
            (r'transform_|convert_|parse_', "Transformation Logic"),
            (r'generate_|create_|build_', "Generation Logic"),
            (r'orchestrate_|coordinate_|manage_', "Orchestration Logic"),
            (r'optimize_|improve_|enhance_', "Optimization Logic"),
            (r'.*', "General Business Logic"),
        ],
        description="Subdivide business logic by operation type"
    )
    
    def __init__(self, enable_ai: bool = True):
        self.strategies = {
            'setter': self.SETTER_STRATEGY,
            'getter': self.GETTER_STRATEGY,
            'business_logic': self.BUSINESS_LOGIC_STRATEGY,
        }
        
        # Target size for subdivided groups
        self.target_group_size = 12
        self.max_group_size = 20
        
        # LLM-based splitting components
        self.llm_group_threshold = 100  # Threshold for LLM-based splitting
        self.rule_repository = SplitRuleRepository()
        self.ai_coordinator = get_ai_coordinator() if enable_ai else None
        self.logger = logging.getLogger(__name__)
    
    def should_split(self, group: FunctionGroup) -> bool:
        """Determine if a group needs splitting based on size."""
        return len(group.functions) > self.max_group_size
    
    def recommend_split_strategy(self, group: FunctionGroup) -> SplitStrategy:
        """Recommend appropriate split strategy based on group type."""
        label_lower = group.label.lower()
        
        if 'setter' in label_lower:
            return self.strategies['setter']
        elif 'getter' in label_lower:
            return self.strategies['getter']
        elif 'business' in label_lower or 'logic' in label_lower:
            return self.strategies['business_logic']
        else:
            # Default: split by common prefixes
            return self._create_prefix_strategy(group)
    
    def _create_prefix_strategy(self, group: FunctionGroup) -> SplitStrategy:
        """Create a splitting strategy based on common prefixes."""
        # Analyze function names to find common prefixes
        prefix_counts = {}
        for func in group.functions:
            name = func.get('name', '')
            # Extract prefix (first word before _)
            parts = name.split('_')
            if len(parts) > 1:
                prefix = parts[0]
                prefix_counts[prefix] = prefix_counts.get(prefix, 0) + 1
        
        # Sort prefixes by frequency
        common_prefixes = sorted(prefix_counts.items(), key=lambda x: x[1], reverse=True)
        
        # Create patterns for top prefixes
        patterns = []
        for prefix, count in common_prefixes[:8]:  # Top 8 prefixes
            if count >= 3:  # At least 3 functions with this prefix
                pattern = f'^{prefix}_'
                label = f"{prefix.title()} Operations"
                patterns.append((pattern, label))
        
        # Add catch-all
        patterns.append((r'.*', f"Other {group.label}"))
        
        return SplitStrategy(
            name=f"{group.label.lower()}_prefix_split",
            patterns=patterns,
            description=f"Split {group.label} by function prefix"
        )
    
    def split_group_intelligently(self, group: FunctionGroup, recursive=True) -> List[FunctionGroup]:
        """Split a large group into smaller, more manageable subgroups."""
        if not self.should_split(group):
            return [group]
        
        strategy = self.recommend_split_strategy(group)
        subgroups = []
        
        # Apply each pattern in order
        remaining_functions = group.functions.copy()
        
        for pattern, label in strategy.patterns:
            if not remaining_functions:
                break
                
            matched_functions = []
            unmatched_functions = []
            
            for func in remaining_functions:
                func_name = func.get('name', '').lower()
                if re.search(pattern, func_name):
                    matched_functions.append(func)
                else:
                    unmatched_functions.append(func)
            
            if matched_functions and len(matched_functions) >= 3:  # Minimum viable group
                subgroup = FunctionGroup(
                    group_id=f"{group.group_id}_sub_{len(subgroups)}",
                    functions=matched_functions,
                    label=f"{label} ({group.label})",
                    confidence=group.confidence * 0.9,  # Slightly lower confidence for subgroups
                    metadata={
                        'parent_group': group.group_id,
                        'split_strategy': strategy.name,
                        'pattern': pattern
                    }
                )
                subgroups.append(subgroup)
                remaining_functions = unmatched_functions
        
        # Handle remaining functions
        if remaining_functions:
            if len(remaining_functions) >= 3:
                subgroup = FunctionGroup(
                    group_id=f"{group.group_id}_sub_other",
                    functions=remaining_functions,
                    label=f"Other {group.label}",
                    confidence=group.confidence * 0.8,
                    metadata={
                        'parent_group': group.group_id,
                        'split_strategy': strategy.name
                    }
                )
                
                # Recursively split if still too large
                if recursive and self.should_split(subgroup):
                    # Create a more specific strategy for the "Other" group
                    other_strategy = self._create_prefix_strategy(subgroup)
                    subgroup.label = group.label  # Temporarily use parent label for better strategy
                    recursive_subgroups = self.split_group_intelligently(subgroup, recursive=False)
                    subgroups.extend(recursive_subgroups)
                else:
                    subgroups.append(subgroup)
            else:
                # Add to the smallest existing subgroup
                if subgroups:
                    smallest = min(subgroups, key=lambda g: len(g.functions))
                    smallest.functions.extend(remaining_functions)
        
        return subgroups
    
    def calculate_split_metrics(self, original_groups: List[FunctionGroup], split_groups: List[FunctionGroup]) -> Dict[str, Any]:
        """Calculate metrics about the splitting operation."""
        original_sizes = [len(g.functions) for g in original_groups]
        split_sizes = [len(g.functions) for g in split_groups]
        
        return {
            'original_groups': len(original_groups),
            'split_groups': len(split_groups),
            'largest_original': max(original_sizes) if original_sizes else 0,
            'largest_split': max(split_sizes) if split_sizes else 0,
            'average_original': sum(original_sizes) / len(original_sizes) if original_sizes else 0,
            'average_split': sum(split_sizes) / len(split_sizes) if split_sizes else 0,
            'groups_over_20': sum(1 for s in split_sizes if s > 20),
            'groups_under_15': sum(1 for s in split_sizes if s <= 15),
            'splitting_factor': len(split_groups) / len(original_groups) if original_groups else 0
        }
    
    async def generate_split_regex_with_llm(self, sample_functions: List[Dict[str, Any]]) -> Tuple[str, str, str, str]:
        """Generate a regex pattern to split functions using LLM with improved prompt handling.
        
        Returns:
            Tuple of (pattern, reasoning, group_a_name, group_b_name)
        """
        if not self.ai_coordinator:
            error_msg = "AI coordinator not available for LLM-based splitting"
            self.logger.error(error_msg)
            raise RuntimeError(error_msg)
        
        # Use centralized prompt handler for consistent formatting with Markdown blocks
        prompt_handler = LLMPromptHandler()
        prompt = prompt_handler.create_pattern_generation_with_classification_prompt(sample_functions)
        
        try:
            response = await self.ai_coordinator.generate_classification_pattern(sample_functions)
            
            if not response or not response.success:
                error_msg = f"LLM response unsuccessful: {response.reasoning if response else 'No response'}"
                self.logger.error(error_msg)
                raise RuntimeError(error_msg)
            
            # Use centralized response parsing with Markdown block support
            result_text = response.result.get('purpose', '') if isinstance(response.result, dict) else str(response.result)
            parsed = prompt_handler.parse_pattern_response(result_text)
            
            self.logger.info(f"LLM generated pattern: {parsed.pattern}")
            self.logger.info(f"LLM reasoning: {parsed.reasoning}")
            self.logger.info(f"Group A name: {parsed.group_a_name}")
            self.logger.info(f"Group B name: {parsed.group_b_name}")
            
            return (
                parsed.pattern, 
                parsed.reasoning or "é–¢æ•°ã‚’2ã¤ã®ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†å‰²",
                parsed.group_a_name or "Group A",
                parsed.group_b_name or "Group B"
            )
            
        except asyncio.TimeoutError:
            error_msg = "LLM request timed out"
            self.logger.error(error_msg)
            raise RuntimeError(error_msg)
        except Exception as e:
            if isinstance(e, RuntimeError):
                raise
            error_msg = f"Unexpected error generating regex with LLM: {e}"
            self.logger.error(error_msg)
            raise RuntimeError(error_msg)
    
    def validate_split(self, group: FunctionGroup, pattern: str) -> Tuple[bool, List[Dict], List[Dict]]:
        """Validate if a regex pattern creates a valid split."""
        try:
            matched = []
            unmatched = []
            
            for func in group.functions:
                code = func.get('code', '')
                if re.search(pattern, code, re.MULTILINE | re.DOTALL):
                    matched.append(func)
                else:
                    unmatched.append(func)
            
            # Valid if both groups have functions
            is_valid = len(matched) > 0 and len(unmatched) > 0
            return is_valid, matched, unmatched
            
        except Exception as e:
            self.logger.error(f"Regex validation failed: {e}")
            return False, [], []
    
    async def split_large_groups_with_llm(self, groups: List[FunctionGroup], max_depth: int = 3, current_depth: int = 0) -> List[FunctionGroup]:
        """Split groups larger than threshold using LLM-generated rules.
        
        Args:
            groups: Groups to split
            max_depth: Maximum recursion depth to prevent infinite loops
            current_depth: Current recursion depth
        """
        # Prevent infinite recursion
        if current_depth >= max_depth:
            self.logger.warning(f"Maximum split depth {max_depth} reached, stopping further splits")
            return groups
        
        result_groups = []
        
        # Apply existing rules first
        try:
            all_rules = self.rule_repository.get_all_rules()
        except Exception as e:
            self.logger.error(f"Failed to retrieve existing rules: {e}")
            # DBã‚¨ãƒ©ãƒ¼ã§ã‚‚å‡¦ç†ã‚’ç¶™ç¶šï¼ˆæ–°è¦ãƒ«ãƒ¼ãƒ«ã‚’ç”Ÿæˆï¼‰
            all_rules = []
        
        for group in groups:
            # Check if group has already been split enough
            split_count = group.metadata.get('split_count', 0)
            if split_count >= max_depth:
                self.logger.info(f"Group {group.group_id} has been split {split_count} times, skipping")
                result_groups.append(group)
                continue
            
            if len(group.functions) <= self.llm_group_threshold:
                result_groups.append(group)
                continue
            
            # Try existing rules
            split_successful = False
            for rule in all_rules:
                try:
                    is_valid, matched, unmatched = self.validate_split(group, rule.pattern)
                    if is_valid:
                        # Create subgroups with incremented split count
                        group_a = FunctionGroup(
                            group_id=f"{group.group_id}_rule_a",
                            functions=matched,
                            label=f"{group.label} (Pattern Match)",
                            confidence=group.confidence * 0.9,
                            metadata={
                                'split_rule': rule.pattern, 
                                'split_reason': rule.reasoning,
                                'split_count': split_count + 1
                            }
                        )
                        group_b = FunctionGroup(
                            group_id=f"{group.group_id}_rule_b",
                            functions=unmatched,
                            label=f"{group.label} (No Match)",
                            confidence=group.confidence * 0.9,
                            metadata={
                                'split_rule': rule.pattern, 
                                'split_reason': rule.reasoning,
                                'split_count': split_count + 1
                            }
                        )
                        
                        # Recursively split if still too large
                        sub_results_a = await self.split_large_groups_with_llm([group_a], max_depth, current_depth + 1)
                        sub_results_b = await self.split_large_groups_with_llm([group_b], max_depth, current_depth + 1)
                        result_groups.extend(sub_results_a)
                        result_groups.extend(sub_results_b)
                        
                        self.rule_repository.update_rule_stats(rule.pattern, True)
                        split_successful = True
                        break
                except Exception as e:
                    self.logger.warning(f"Failed to apply rule '{rule.pattern}': {e}")
                    continue
            
            if split_successful:
                continue
            
            # Generate new rule with LLM
            max_attempts = 3
            for attempt in range(max_attempts):
                # Sample functions (5 or all if less)
                sample_size = min(5, len(group.functions))
                sample_functions = random.sample(group.functions, sample_size)
                
                try:
                    pattern, reasoning, group_a_name, group_b_name = await self.generate_split_regex_with_llm(sample_functions)
                    is_valid, matched, unmatched = self.validate_split(group, pattern)
                    
                    if is_valid:
                        # Save new rule
                        new_rule = SplitRule(
                            pattern=pattern,
                            reasoning=reasoning,
                            created_at=datetime.now()
                        )
                        
                        try:
                            self.rule_repository.save_rule(new_rule)
                        except Exception as e:
                            self.logger.warning(f"Failed to save rule to DB: {e}")
                            # ãƒ«ãƒ¼ãƒ«ä¿å­˜å¤±æ•—ã§ã‚‚åˆ†å‰²å‡¦ç†ã¯ç¶™ç¶š
                        
                        # Create subgroups with meaningful names and incremented split count
                        group_a = FunctionGroup(
                            group_id=f"{group.group_id}_llm_a",
                            functions=matched,
                            label=group_a_name,
                            confidence=group.confidence * 0.85,
                            metadata={
                                'split_rule': pattern, 
                                'split_reason': reasoning,
                                'split_count': split_count + 1,
                                'parent_group': group.group_id
                            }
                        )
                        group_b = FunctionGroup(
                            group_id=f"{group.group_id}_llm_b",
                            functions=unmatched,
                            label=group_b_name,
                            confidence=group.confidence * 0.85,
                            metadata={
                                'split_rule': pattern, 
                                'split_reason': reasoning,
                                'split_count': split_count + 1,
                                'parent_group': group.group_id
                            }
                        )
                        
                        # Recursively split if still too large
                        sub_results_a = await self.split_large_groups_with_llm([group_a], max_depth, current_depth + 1)
                        sub_results_b = await self.split_large_groups_with_llm([group_b], max_depth, current_depth + 1)
                        result_groups.extend(sub_results_a)
                        result_groups.extend(sub_results_b)
                        
                        self.logger.info(f"Successfully split group {group.group_id} with LLM rule: {pattern}")
                        break
                    else:
                        self.logger.warning(f"Generated pattern '{pattern}' did not create valid split")
                    
                except RuntimeError as e:
                    self.logger.error(f"Attempt {attempt + 1} failed with error: {e}")
                    if attempt == max_attempts - 1:
                        # æœ€å¾Œã®è©¦è¡Œã§ã‚‚ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ä¸Šä½ã«ä¼æ’­
                        raise RuntimeError(f"Cannot split group {group.group_id}: {e}")
                except Exception as e:
                    self.logger.error(f"Unexpected error in attempt {attempt + 1}: {e}")
                    if attempt == max_attempts - 1:
                        raise RuntimeError(f"Unexpected error splitting group {group.group_id}: {e}")
                    
                if attempt == max_attempts - 1:
                    # Failed to split after all attempts
                    error_msg = f"Failed to split group {group.group_id} after {max_attempts} attempts"
                    self.logger.error(error_msg)
                    raise RuntimeError(error_msg)
        
        return result_groups


async def demo_llm_splitting():
    """Demo the LLM-based group splitting functionality."""
    print("ðŸ¤– LLM-based Smart Group Splitter Demo")
    print("=" * 50)
    
    # Create a mock large group
    mock_functions = []
    
    # Generate 150 diverse functions
    patterns = [
        ('validate_', 'email|password|input|data|format'),
        ('process_', 'data|request|response|file|image'),
        ('handle_', 'error|exception|request|event|callback'),
        ('calculate_', 'total|average|sum|percentage|score'),
        ('test_', 'unit|integration|api|validation|performance'),
        ('get_', 'user|data|config|status|info'),
        ('set_', 'value|config|state|property|attribute'),
        ('create_', 'object|instance|file|connection|resource'),
        ('update_', 'record|status|data|cache|database'),
        ('delete_', 'file|record|cache|temp|resource')
    ]
    
    for prefix, suffixes in patterns:
        suffix_list = suffixes.split('|')
        for i in range(15):  # 15 functions per pattern
            suffix = suffix_list[i % len(suffix_list)]
            mock_functions.append({
                'name': f"{prefix}{suffix}_{i}",
                'code': f"def {prefix}{suffix}_{i}():\n    # {prefix} operation\n    pass",
                'file_path': f"module_{prefix.strip('_')}.py"
            })
    
    large_group = FunctionGroup(
        group_id="mixed_functions",
        functions=mock_functions,
        label="Mixed Functions",
        confidence=0.7,
        metadata={}
    )
    
    # Initialize splitter with AI
    splitter = SmartGroupSplitter(enable_ai=True)
    
    print(f"Original group: {large_group.label} ({len(large_group.functions)} functions)")
    print(f"Threshold for LLM splitting: {splitter.llm_group_threshold} functions")
    
    # Perform LLM-based splitting
    result_groups = await splitter.split_large_groups_with_llm([large_group])
    
    print(f"\nSplit into {len(result_groups)} groups:")
    for i, group in enumerate(result_groups, 1):
        print(f"  {i}. {group.label}: {len(group.functions)} functions")
        if 'split_reason' in group.metadata:
            print(f"     Reason: {group.metadata['split_reason'][:50]}...")
    
    # Show saved rules
    rules = splitter.rule_repository.get_all_rules()
    if rules:
        print(f"\nðŸ“ Generated Split Rules ({len(rules)} total):")
        for rule in rules[:3]:  # Show first 3 rules
            print(f"  Pattern: {rule.pattern}")
            print(f"  Reasoning: {rule.reasoning[:60]}...")
            print()


def demo_smart_splitting():
    """Demo the smart group splitting functionality."""
    print("ðŸ”ª Smart Group Splitter Demo")
    print("=" * 40)
    
    # Create a mock large setter group
    mock_setters = []
    setter_patterns = [
        ('set_config_value', 'config'),
        ('set_user_state', 'state'),
        ('update_profile', 'update'),
        ('save_to_database', 'save'),
        ('write_to_file', 'write'),
        ('register_handler', 'register'),
        ('apply_changes', 'apply')
    ]
    
    # Generate mock functions
    for base_name, category in setter_patterns:
        for i in range(20):  # 20 functions per pattern = 140 total
            mock_setters.append({
                'name': f"{base_name}_{i}",
                'category': category,
                'file_path': f"module_{category}.py"
            })
    
    large_group = FunctionGroup(
        group_id="setters_main",
        functions=mock_setters[:129],  # Simulate the actual 129 setter functions
        label="Setter Functions",
        confidence=0.6,
        metadata={}
    )
    
    # Split the group
    splitter = SmartGroupSplitter()
    
    print(f"Original group: {large_group.label} ({len(large_group.functions)} functions)")
    print(f"Should split: {splitter.should_split(large_group)}")
    
    # Perform splitting
    subgroups = splitter.split_group_intelligently(large_group)
    
    print(f"\nSplit into {len(subgroups)} subgroups:")
    for i, subgroup in enumerate(subgroups, 1):
        print(f"  {i}. {subgroup.label}: {len(subgroup.functions)} functions")
    
    # Calculate metrics
    metrics = splitter.calculate_split_metrics([large_group], subgroups)
    print(f"\nSplitting metrics:")
    print(f"  Largest group reduced from {metrics['largest_original']} to {metrics['largest_split']}")
    print(f"  Average group size: {metrics['average_original']:.1f} â†’ {metrics['average_split']:.1f}")
    print(f"  Groups â‰¤15 functions: {metrics['groups_under_15']}/{metrics['split_groups']}")


if __name__ == "__main__":
    import asyncio
    # Run async demo
    asyncio.run(demo_llm_splitting())
    # Run sync demo
    demo_smart_splitting()