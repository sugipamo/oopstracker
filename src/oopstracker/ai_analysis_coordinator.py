"""
AI Analysis Coordinator - Application layer component for AI analysis coordination.
Replaces the confusing "UnifiedLLMService" naming with proper layer terminology.
"""

import asyncio
import logging
import re
import sqlite3
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass
from abc import ABC, abstractmethod
from pathlib import Path
from datetime import datetime

try:
    from intent_unified.core.semantic_analyzer import SemanticDuplicateAnalyzer, UnifiedConfig
    from llm_providers import create_provider, LLMConfig
    AI_AVAILABLE = True
except ImportError as e:
    AI_AVAILABLE = False


@dataclass
class AnalysisRequest:
    """Request for AI analysis."""
    request_type: str  # 'similarity', 'classification', 'intent_analysis'
    content: Union[str, List[str]]
    context: Optional[Dict[str, Any]] = None
    timeout: Optional[float] = None  # Use LLM-Providers default
    temperature: float = 0.1


@dataclass
class ClassificationRule:
    """A classification rule generated by LLM."""
    pattern: str
    category: str
    reasoning: str
    created_at: datetime
    success_count: int = 0
    failure_count: int = 0


@dataclass 
class AnalysisResponse:
    """Response from AI analysis."""
    success: bool
    result: Any
    confidence: float
    reasoning: str
    metadata: Dict[str, Any]
    processing_time: float


class ClassificationRuleRepository:
    """Repository for managing classification rules in SQLite."""
    
    def __init__(self, db_path: str = "classification_rules.db"):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)
        self._init_database()
    
    def _init_database(self):
        """Initialize the database schema."""
        try:
            # Ensure directory exists
            db_dir = Path(self.db_path).parent
            if db_dir != Path('.'):
                db_dir.mkdir(parents=True, exist_ok=True)
            
            with sqlite3.connect(self.db_path) as conn:
                conn.execute('''
                    CREATE TABLE IF NOT EXISTS classification_rules (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        pattern TEXT NOT NULL,
                        category TEXT NOT NULL,
                        reasoning TEXT NOT NULL,
                        created_at TEXT NOT NULL,
                        success_count INTEGER DEFAULT 0,
                        failure_count INTEGER DEFAULT 0
                    )
                ''')
                conn.commit()
                
                # Add default rules if table is empty
                cursor = conn.execute("SELECT COUNT(*) FROM classification_rules")
                if cursor.fetchone()[0] == 0:
                    self._add_default_rules(conn)
                    
        except sqlite3.Error as e:
            self.logger.error(f"Failed to initialize classification rules database: {e}")
            raise RuntimeError(f"Cannot initialize database at {self.db_path}: {e}")
    
    def _add_default_rules(self, conn: sqlite3.Connection):
        """Add default classification rules for common patterns."""
        default_rules = [
            # Test functions
            ClassificationRule(
                pattern=r"def\s+test_\w+|def\s+\w+_test",
                category="test",
                reasoning="Test function pattern",
                created_at=datetime.now()
            ),
            # Getter/Setter
            ClassificationRule(
                pattern=r"def\s+(get|set)_\w+|def\s+(get|set)[A-Z]\w*",
                category="getter_setter",
                reasoning="Getter/setter method pattern",
                created_at=datetime.now()
            ),
            # Main entry points
            ClassificationRule(
                pattern=r"def\s+main\s*\(|if\s+__name__\s*==\s*['\"]__main__['\"]",
                category="utility",
                reasoning="Main entry point pattern",
                created_at=datetime.now()
            ),
            # Initialization
            ClassificationRule(
                pattern=r"def\s+__init__\s*\(",
                category="constructor",
                reasoning="Class constructor pattern",
                created_at=datetime.now()
            ),
            # API endpoints
            ClassificationRule(
                pattern=r"@(app|router)\.(get|post|put|delete|patch)",
                category="web_api",
                reasoning="Web API endpoint pattern",
                created_at=datetime.now()
            ),
            # Data processing
            ClassificationRule(
                pattern=r"def\s+(parse|process|transform|convert|extract)_\w+",
                category="data_processing",
                reasoning="Data processing function pattern",
                created_at=datetime.now()
            ),
            # Business logic
            ClassificationRule(
                pattern=r"def\s+(calculate|compute|validate|check|verify)_\w+",
                category="business_logic",
                reasoning="Business logic function pattern",
                created_at=datetime.now()
            ),
            # Simple utility
            ClassificationRule(
                pattern=r"def\s+\w+\s*\(\s*\)\s*:\s*(pass|\.\.\.|\n\s+return)",
                category="utility",
                reasoning="Simple utility function pattern",
                created_at=datetime.now()
            ),
        ]
        
        for rule in default_rules:
            try:
                conn.execute('''
                    INSERT INTO classification_rules (pattern, category, reasoning, created_at, success_count, failure_count)
                    VALUES (?, ?, ?, ?, 0, 0)
                ''', (rule.pattern, rule.category, rule.reasoning, rule.created_at.isoformat()))
            except sqlite3.Error:
                # Ignore duplicates
                pass
        
        conn.commit()
        self.logger.info(f"Added {len(default_rules)} default classification rules")
    
    def save_rule(self, rule: ClassificationRule) -> int:
        """Save a classification rule to the database."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    INSERT INTO classification_rules (pattern, category, reasoning, created_at, success_count, failure_count)
                    VALUES (?, ?, ?, ?, ?, ?)
                ''', (rule.pattern, rule.category, rule.reasoning, rule.created_at.isoformat(), 
                      rule.success_count, rule.failure_count))
                conn.commit()
                return cursor.lastrowid
        except sqlite3.Error as e:
            self.logger.error(f"Failed to save classification rule: {e}")
            raise RuntimeError(f"Cannot save rule to database: {e}")
    
    def get_rules_for_category(self, category: str) -> List[ClassificationRule]:
        """Get all rules for a specific category, ordered by success rate."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    SELECT pattern, category, reasoning, created_at, success_count, failure_count
                    FROM classification_rules
                    WHERE category = ?
                    ORDER BY (success_count * 1.0 / (success_count + failure_count + 1)) DESC,
                             success_count DESC, created_at DESC
                ''', (category,))
                
                rules = []
                for row in cursor.fetchall():
                    try:
                        rules.append(ClassificationRule(
                            pattern=row[0],
                            category=row[1],
                            reasoning=row[2],
                            created_at=datetime.fromisoformat(row[3]),
                            success_count=row[4],
                            failure_count=row[5]
                        ))
                    except Exception as e:
                        self.logger.warning(f"Skipping invalid rule record: {e}")
                        continue
                return rules
        except sqlite3.Error as e:
            self.logger.error(f"Failed to retrieve rules: {e}")
            return []
    
    def get_all_rules(self) -> List[ClassificationRule]:
        """Get all classification rules."""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute('''
                    SELECT pattern, category, reasoning, created_at, success_count, failure_count
                    FROM classification_rules
                    ORDER BY success_count DESC, created_at DESC
                ''')
                
                rules = []
                for row in cursor.fetchall():
                    try:
                        rules.append(ClassificationRule(
                            pattern=row[0],
                            category=row[1],
                            reasoning=row[2],
                            created_at=datetime.fromisoformat(row[3]),
                            success_count=row[4],
                            failure_count=row[5]
                        ))
                    except Exception as e:
                        self.logger.warning(f"Skipping invalid rule record: {e}")
                        continue
                return rules
        except sqlite3.Error as e:
            self.logger.error(f"Failed to retrieve all rules: {e}")
            return []
    
    def update_rule_stats(self, pattern: str, category: str, success: bool):
        """Update success/failure statistics for a rule."""
        try:
            field = "success_count" if success else "failure_count"
            with sqlite3.connect(self.db_path) as conn:
                conn.execute(f'''
                    UPDATE classification_rules
                    SET {field} = {field} + 1
                    WHERE pattern = ? AND category = ?
                ''', (pattern, category))
                conn.commit()
        except sqlite3.Error as e:
            self.logger.error(f"Failed to update rule stats: {e}")


class AIAnalysisInterface(ABC):
    """Interface for AI analysis capabilities."""
    
    @abstractmethod
    async def analyze_similarity(self, code1: str, code2: str, **kwargs) -> AnalysisResponse:
        """Analyze semantic similarity between two code snippets."""
        pass
    
    @abstractmethod
    async def classify_function(self, code: str, categories: List[str], **kwargs) -> AnalysisResponse:
        """Classify a function into predefined categories."""
        pass
    
    @abstractmethod
    async def analyze_intent(self, code: str, **kwargs) -> AnalysisResponse:
        """Analyze the intent/purpose of code."""
        pass


class AIAnalysisCoordinator(AIAnalysisInterface):
    """
    Coordinates AI analysis requests across the application.
    
    This is an application layer component that orchestrates AI analysis
    without exposing low-level AI service details to the domain layer.
    """
    
    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self._semantic_analyzer = None
        self._llm_provider = None
        self._available = False
        self._initialized = False
        
        # Initialize rule-based classification
        self.rule_repository = ClassificationRuleRepository()
        
        if AI_AVAILABLE:
            self._init_available = True
        else:
            self._init_available = False
            self.logger.error("AI not available - LLM configuration required")
            raise RuntimeError("AI services are not available. Please install and configure LLM dependencies.")
    
    async def cleanup(self):
        """Clean up resources."""
        if self._llm_provider:
            await self._llm_provider.cleanup()
        if self._semantic_analyzer:
            await self._semantic_analyzer.cleanup()
    
    async def __aenter__(self):
        """Async context manager entry."""
        await self._ensure_initialized()
        return self
        
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Async context manager exit."""
        await self.cleanup()
    
    async def _ensure_initialized(self):
        """Ensure AI components are initialized."""
        if self._initialized or not self._init_available:
            return
            
        try:
            # Create config for semantic analyzer
            unified_config = UnifiedConfig.from_env()
            self._semantic_analyzer = SemanticDuplicateAnalyzer(unified_config)
            
            # Initialize LLM provider using PresetManager
            from llm_providers import PresetManager
            
            preset_manager = PresetManager()
            preset = preset_manager.get_default_preset()
            
            if not preset:
                raise RuntimeError("No LLM presets configured. Please use 'llm-providers presets add' to configure an LLM endpoint.")
            
            self.logger.info(f"Using preset '{preset.name}'")
            
            config = LLMConfig(
                provider=preset.provider_type,
                model=preset.model,
                base_url=preset.base_url,
                temperature=preset.temperature,
                max_tokens=preset.max_tokens,
                timeout=preset.timeout,
                retry_count=3,
                retry_delay=0.5
            )
            self._llm_provider = await create_provider(config)
            self._available = True
            self._initialized = True
            self.logger.info(f"AI analysis coordinator initialized with LLM preset '{preset.name}' at {config.base_url}")
        except Exception as e:
            self.logger.warning(f"Failed to initialize AI analyzer: {e}")
            self._available = False
            self._initialized = True
    
    @property
    def available(self) -> bool:
        """Check if AI analysis is available."""
        # Return true if dependencies are available (will be initialized on first use)
        return self._init_available
    
    async def analyze_similarity(self, code1: str, code2: str, **kwargs) -> AnalysisResponse:
        """Coordinate similarity analysis between two code snippets."""
        start_time = asyncio.get_event_loop().time()
        
        await self._ensure_initialized()
        
        if not self._available:
            raise RuntimeError("AI analysis is not available. Please configure LLM settings.")
        
        try:
            timeout = kwargs.get('timeout', None)  # Use LLM-Providers default
            language = kwargs.get('language', 'python')
            
            # Use semantic analyzer for similarity
            if timeout:
                similarity = await asyncio.wait_for(
                    self._semantic_analyzer.analyze_similarity(
                        code1, code2
                    ),
                    timeout=timeout
                )
            else:
                # Use LLM-Providers default timeout
                similarity = await self._semantic_analyzer.analyze_similarity(
                    code1, code2
                )
            
            processing_time = asyncio.get_event_loop().time() - start_time
            
            return AnalysisResponse(
                success=True,
                result=similarity,
                confidence=0.9,
                reasoning="Semantic similarity computed using AI analysis",
                metadata={
                    "language": language,
                    "analysis_method": "ai_semantic"
                },
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = asyncio.get_event_loop().time() - start_time
            self.logger.error(f"AI similarity analysis failed: {e}")
            
            return AnalysisResponse(
                success=False,
                result=0.0,
                confidence=0.0,
                reasoning=f"Analysis failed: {str(e)[:100]}",
                metadata={"error": str(e)},
                processing_time=processing_time
            )
    
    async def classify_function(self, code: str, categories: List[str], **kwargs) -> AnalysisResponse:
        """
        Coordinate function classification using rule-based approach with LLM fallback.
        
        Process:
        1. Try existing rules first (fast, no LLM call)
        2. If no rules match, generate new rule with LLM  
        3. Apply new rule and save for future use
        """
        start_time = asyncio.get_event_loop().time()
        
        # Step 1: Try existing rules first
        rule_result = self._apply_classification_rules(code, categories)
        if rule_result:
            category, confidence, reasoning, rule_pattern = rule_result
            
            processing_time = asyncio.get_event_loop().time() - start_time
            return AnalysisResponse(
                success=True,
                result=category,
                confidence=confidence,
                reasoning=f"Rule-based: {reasoning}",
                metadata={
                    "analysis_method": "rule_based",
                    "rule_pattern": rule_pattern,
                    "available_categories": categories
                },
                processing_time=processing_time
            )
        
        # Step 2: No existing rules worked, need LLM to generate new rule
        await self._ensure_initialized()
        
        if not self._available:
            raise RuntimeError("AI analysis is not available and no classification rules match.")
        
        try:
            # Generate new classification rule using LLM
            new_rule = await self._generate_classification_rule(code, categories)
            
            if new_rule:
                # Save the new rule for future use
                try:
                    self.rule_repository.save_rule(new_rule)
                    self.logger.info(f"Saved new classification rule: {new_rule.pattern} -> {new_rule.category}")
                except Exception as e:
                    self.logger.warning(f"Failed to save new rule: {e}")
                
                # Apply the new rule to current code
                if re.search(new_rule.pattern, code, re.IGNORECASE):
                    processing_time = asyncio.get_event_loop().time() - start_time
                    return AnalysisResponse(
                        success=True,
                        result=new_rule.category,
                        confidence=0.8,  # Slightly lower confidence for new rules
                        reasoning=f"New rule: {new_rule.reasoning}",
                        metadata={
                            "analysis_method": "new_rule_generation",
                            "rule_pattern": new_rule.pattern,
                            "available_categories": categories
                        },
                        processing_time=processing_time
                    )
            
            # Fallback: direct LLM classification
            processing_time = asyncio.get_event_loop().time() - start_time
            return AnalysisResponse(
                success=False,
                result="unknown",
                confidence=0.0,
                reasoning="Failed to generate applicable classification rule",
                metadata={"error": "Rule generation failed"},
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = asyncio.get_event_loop().time() - start_time
            self.logger.error(f"Classification failed: {e}")
            
            return AnalysisResponse(
                success=False,
                result="unknown",
                confidence=0.0,
                reasoning=f"Classification failed: {str(e)[:100]}",
                metadata={"error": str(e)},
                processing_time=processing_time
            )
    
    async def _llm_self_extract_classification(self, response_text: str, categories: List[str]) -> Tuple[Optional[str], float, str]:
        """
        Use LLM self-reflection to extract classification from unstructured response.
        
        This is more robust than regex patterns because:
        - Language-agnostic
        - Handles creative expressions  
        - Self-correcting
        - Easier to maintain
        
        Args:
            response_text: Original LLM response
            categories: Available categories
            
        Returns:
            Tuple of (category, confidence, reasoning) or (None, 0.0, error_msg)
        """
        
        extraction_prompt = f"""The following is an AI response about function classification:

"{response_text}"

Please extract the classification information from this response and format it exactly as shown:

Available categories: {', '.join(categories)}

REQUIRED OUTPUT FORMAT:
category: [one of: {', '.join(categories)}]
confidence: [0.0-1.0]
reasoning: [brief explanation]

If the response doesn't clearly indicate a category, respond with:
category: unknown
confidence: 0.0
reasoning: No clear classification found

EXTRACT NOW:"""
        
        try:
            # Use the LLM to parse its own response
            extract_response = await self._llm_provider.generate(extraction_prompt)
            extract_text = extract_response.content if hasattr(extract_response, 'content') else str(extract_response)
            
            # Parse the structured extraction (simpler regex - just for structured output)
            import re
            category_match = re.search(r'category:\s*([^\n\r]+)', extract_text, re.IGNORECASE)
            confidence_match = re.search(r'confidence:\s*([^\n\r]+)', extract_text, re.IGNORECASE)
            reasoning_match = re.search(r'reasoning:\s*([^\n\r]+)', extract_text, re.IGNORECASE)
            
            if category_match:
                category = category_match.group(1).strip().lower()
                confidence = float(confidence_match.group(1).strip()) if confidence_match else 0.4
                reasoning = reasoning_match.group(1).strip() if reasoning_match else "Self-extracted from response"
                
                # Validate category
                if category in [c.lower() for c in categories]:
                    return category, confidence * 0.8, f"Self-reflection: {reasoning}"  # Slight confidence penalty for indirection
                else:
                    return None, 0.0, f"Invalid category from self-extraction: {category}"
            else:
                return None, 0.0, "Self-extraction failed to find category"
                
        except Exception as e:
            self.logger.warning(f"LLM self-extraction failed: {e}")
            return None, 0.0, f"Self-extraction error: {str(e)}"
    
    async def _llm_self_extract_intent(self, response_text: str) -> Tuple[Optional[str], Optional[str], float]:
        """
        Use LLM self-reflection to extract intent information from unstructured response.
        
        Args:
            response_text: Original LLM response about code intent
            
        Returns:
            Tuple of (purpose, functionality, confidence)
        """
        
        extraction_prompt = f"""The following is an AI response about code analysis:

"{response_text}"

Please extract the key information and format it exactly as shown:

REQUIRED OUTPUT FORMAT:
purpose: [main purpose in 1-2 sentences]
functionality: [specific functionality description]
confidence: [0.0-1.0]

If no clear intent is described, respond with:
purpose: Unknown function purpose
functionality: General functionality
confidence: 0.3

EXTRACT NOW:"""
        
        try:
            extract_response = await self._llm_provider.generate(extraction_prompt)
            extract_text = extract_response.content if hasattr(extract_response, 'content') else str(extract_response)
            
            import re
            purpose_match = re.search(r'purpose:\s*([^\n\r]+)', extract_text, re.IGNORECASE)
            functionality_match = re.search(r'functionality:\s*([^\n\r]+)', extract_text, re.IGNORECASE)
            confidence_match = re.search(r'confidence:\s*([^\n\r]+)', extract_text, re.IGNORECASE)
            
            if purpose_match:
                purpose = purpose_match.group(1).strip()
                functionality = functionality_match.group(1).strip() if functionality_match else "General functionality"
                confidence = float(confidence_match.group(1).strip()) if confidence_match else 0.5
                
                return purpose, functionality, confidence * 0.8  # Slight penalty for indirection
            else:
                return None, None, 0.3
                
        except Exception as e:
            self.logger.warning(f"Intent self-extraction failed: {e}")
            return None, None, 0.3
    
    def _apply_classification_rules(self, code: str, categories: List[str]) -> Optional[Tuple[str, float, str, str]]:
        """
        Apply existing classification rules to code.
        
        Returns:
            Tuple of (category, confidence, reasoning, pattern) or None if no match
        """
        # Get all rules and try them in order of effectiveness
        all_rules = self.rule_repository.get_all_rules()
        
        for rule in all_rules:
            # Only consider rules for the requested categories
            if rule.category not in [c.lower() for c in categories]:
                continue
                
            try:
                if re.search(rule.pattern, code, re.IGNORECASE):
                    # Calculate confidence based on rule success rate
                    total_attempts = rule.success_count + rule.failure_count
                    if total_attempts > 0:
                        success_rate = rule.success_count / total_attempts
                        confidence = min(0.95, 0.7 + (success_rate * 0.2))  # 0.7-0.95 range
                    else:
                        confidence = 0.8  # Default for untested rules
                    
                    # Update rule statistics
                    self.rule_repository.update_rule_stats(rule.pattern, rule.category, True)
                    
                    return rule.category, confidence, rule.reasoning, rule.pattern
                    
            except re.error as e:
                self.logger.warning(f"Invalid regex pattern in rule: {rule.pattern} - {e}")
                continue
        
        return None
    
    async def _generate_classification_rule(self, code: str, categories: List[str]) -> Optional[ClassificationRule]:
        """
        Generate a new classification rule using LLM.
        
        Returns:
            New ClassificationRule or None if generation failed
        """
        
        # Use the LLMPromptHandler for consistent prompt generation
        from .llm_prompt_handler import LLMPromptHandler
        
        # Create a mock function for the prompt handler
        mock_functions = [{'name': 'unknown_function', 'code': code}]
        
        prompt_handler = LLMPromptHandler()
        prompt = prompt_handler.create_pattern_generation_with_classification_prompt(mock_functions)
        
        # Modify the prompt to focus on single function classification
        # Choose appropriate example based on available categories
        if 'data_processing' in categories:
            example_category = 'data_processing'
            example_pattern = 'def\\s+(process|transform|parse)_\\w+_data'
            example_reasoning = 'Transforms and validates input data structures'
        elif 'utility' in categories:
            example_category = 'utility'
            example_pattern = 'def\\s+\\w+_helper|def\\s+get_\\w+'
            example_reasoning = 'Helper function for common operations'
        else:
            example_category = categories[0]
            example_pattern = 'def\\s+\\w+'
            example_reasoning = 'General function pattern'
            
        classification_prompt = f"""Function:
```python
{code}
```

Categories: {', '.join(categories)}

Example classification format:
```classification
pattern: {example_pattern}
group_a_name: {example_category}
reasoning: {example_reasoning}
```

Based on the function above and available categories, provide a complete classification in the EXACT same format:"""
        
        try:
            # Generate rule using LLM
            llm_response = await self._llm_provider.generate(classification_prompt)
            response_text = llm_response.content if hasattr(llm_response, 'content') else str(llm_response)
            
            # Parse the response using the prompt handler
            parsed = prompt_handler.parse_classification_block(response_text)
            
            if parsed.pattern and parsed.group_a_name:
                # Validate the generated pattern
                try:
                    re.compile(parsed.pattern)
                    
                    # Determine the category (use group_a_name as the category)
                    category = parsed.group_a_name.lower()
                    if category not in [c.lower() for c in categories]:
                        # Try to map to a valid category
                        category = self._map_to_valid_category(category, categories)
                    
                    if category:
                        return ClassificationRule(
                            pattern=parsed.pattern,
                            category=category,
                            reasoning=parsed.reasoning or "LLM-generated classification rule",
                            created_at=datetime.now()
                        )
                        
                except re.error as e:
                    self.logger.warning(f"Generated invalid regex pattern: {parsed.pattern} - {e}")
                    
        except Exception as e:
            self.logger.error(f"Failed to generate classification rule: {e}")
        
        return None
    
    def _map_to_valid_category(self, suggested_category: str, valid_categories: List[str]) -> Optional[str]:
        """Map a suggested category to a valid one."""
        suggested_lower = suggested_category.lower()
        
        # Direct mapping
        category_mappings = {
            'data_retrieval': 'getter',
            'data_access': 'getter', 
            'accessor': 'getter',
            'retrieve': 'getter',
            'fetch': 'getter',
            'load': 'getter',
            
            'data_modification': 'setter',
            'modifier': 'setter',
            'update': 'setter',
            'save': 'setter',
            'write': 'setter',
            
            'processing': 'business_logic',
            'logic': 'business_logic',
            'computation': 'business_logic',
            'calculation': 'business_logic',
        }
        
        mapped = category_mappings.get(suggested_lower)
        if mapped and mapped in [c.lower() for c in valid_categories]:
            return mapped
        
        # Fuzzy matching
        for valid_cat in valid_categories:
            if suggested_lower in valid_cat.lower() or valid_cat.lower() in suggested_lower:
                return valid_cat.lower()
        
        return None
    
    async def generate_classification_pattern(self, sample_functions: List[Dict[str, Any]], **kwargs) -> AnalysisResponse:
        """Generate a regex pattern for splitting functions using LLM.
        
        Args:
            sample_functions: List of function dictionaries with 'name' and 'code' keys
            
        Returns:
            AnalysisResponse with classification pattern data
        """
        start_time = asyncio.get_event_loop().time()
        
        await self._ensure_initialized()
        
        if not self._available:
            raise RuntimeError("AI analysis is not available. Please configure LLM settings.")
        
        try:
            # Use the prompt handler to create the pattern generation prompt
            from .llm_prompt_handler import LLMPromptHandler
            
            prompt_handler = LLMPromptHandler()
            pattern_prompt = prompt_handler.create_pattern_generation_with_classification_prompt(sample_functions)
            
            # Use LLM provider for pattern generation
            llm_response = await self._llm_provider.generate(pattern_prompt)
            response_text = llm_response.content if hasattr(llm_response, 'content') else str(llm_response)
            
            # Parse the response using the prompt handler
            parsed = prompt_handler.parse_classification_block(response_text)
            
            processing_time = asyncio.get_event_loop().time() - start_time
            
            return AnalysisResponse(
                success=True,
                result={
                    "pattern": parsed.pattern,
                    "reasoning": parsed.reasoning,
                    "group_a_name": parsed.group_a_name,
                    "group_b_name": parsed.group_b_name
                },
                confidence=parsed.confidence,
                reasoning="Classification pattern generated using LLM",
                metadata={
                    "analysis_method": "pattern_generation",
                    "pattern": parsed.pattern
                },
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = asyncio.get_event_loop().time() - start_time
            self.logger.error(f"Pattern generation failed: {e}")
            
            return AnalysisResponse(
                success=False,
                result={"pattern": None, "reasoning": None, "group_a_name": None, "group_b_name": None},
                confidence=0.0,
                reasoning=f"Pattern generation failed: {str(e)[:100]}",
                metadata={"error": str(e)},
                processing_time=processing_time
            )
    
    async def analyze_intent(self, code: str, **kwargs) -> AnalysisResponse:
        """Coordinate intent analysis of code."""
        start_time = asyncio.get_event_loop().time()
        
        await self._ensure_initialized()
        
        if not self._available:
            raise RuntimeError("AI analysis is not available. Please configure LLM settings.")
        
        try:
            intent_prompt = f"""Analyze the purpose and functionality of this code:

```python
{code}
```

REQUIRED RESPONSE FORMAT:
```analysis
purpose: <main purpose in 1-2 sentences>
functionality: <specific functionality description>
confidence: <confidence level 0.0-1.0>
```

EXAMPLE:
```analysis
purpose: Retrieve user information from database
functionality: Takes ID and executes SQL query to return user dictionary
confidence: 0.9
```

IMPORTANT:
- MUST use the exact markdown block format above
- No additional explanations outside the block
- Keep responses concise and structured"""
            
            # Use LLM provider for intent analysis
            llm_response = await self._llm_provider.generate(intent_prompt)
            response_text = llm_response.content if hasattr(llm_response, 'content') else str(llm_response)
            
            # Parse response flexibly (try Markdown block first, then fallback to text extraction)
            import re
            try:
                # Try Markdown block format first
                analysis_match = re.search(
                    r'```analysis\s*\n(.*?)\n```', 
                    response_text, 
                    re.DOTALL | re.IGNORECASE
                )
                
                if analysis_match:
                    block_content = analysis_match.group(1).strip()
                    
                    # Extract fields from block
                    purpose_match = re.search(r'purpose:\s*([^\n\r]+)', block_content, re.IGNORECASE)
                    functionality_match = re.search(r'functionality:\s*([^\n\r]+)', block_content, re.IGNORECASE)
                    confidence_match = re.search(r'confidence:\s*([^\n\r]+)', block_content, re.IGNORECASE)
                    
                    purpose = purpose_match.group(1).strip() if purpose_match else "General purpose function"
                    functionality = functionality_match.group(1).strip() if functionality_match else "General functionality"
                    confidence = float(confidence_match.group(1).strip()) if confidence_match else 0.7
                else:
                    # Fallback: extract from any text format or analyze content
                    purpose_match = re.search(r'purpose:\s*([^\n\r]+)', response_text, re.IGNORECASE)
                    functionality_match = re.search(r'functionality:\s*([^\n\r]+)', response_text, re.IGNORECASE)
                    
                    if purpose_match:
                        purpose = purpose_match.group(1).strip()
                        functionality = functionality_match.group(1).strip() if functionality_match else "General functionality"
                        confidence = 0.7
                    else:
                        # LLM self-reflection for intent extraction
                        purpose, functionality, confidence = await self._llm_self_extract_intent(response_text)
                        if not purpose:
                            purpose = "Unknown purpose"
                            functionality = "General functionality"
                            confidence = 0.3
                    
            except (ValueError, AttributeError) as parse_error:
                self.logger.warning(f"Failed to parse LLM intent response: {parse_error}")
                purpose = "General purpose function"
                functionality = "General functionality"
                confidence = 0.3
            
            processing_time = asyncio.get_event_loop().time() - start_time
            
            return AnalysisResponse(
                success=True,
                result={
                    "purpose": purpose,
                    "functionality": functionality
                },
                confidence=confidence,
                reasoning="Intent analyzed using AI",
                metadata={
                    "analysis_method": "ai_intent_analysis"
                },
                processing_time=processing_time
            )
            
        except Exception as e:
            processing_time = asyncio.get_event_loop().time() - start_time
            self.logger.error(f"AI intent analysis failed: {e}")
            
            return AnalysisResponse(
                success=False,
                result={"purpose": "Unknown", "functionality": "Unknown"},
                confidence=0.0,
                reasoning=f"Intent analysis failed: {str(e)[:100]}",
                metadata={"error": str(e)},
                processing_time=processing_time
            )
    




# Singleton instance
_ai_coordinator = None

def get_ai_coordinator() -> AIAnalysisInterface:
    """Get singleton instance of AI coordinator."""
    global _ai_coordinator
    
    if _ai_coordinator is None:
        _ai_coordinator = AIAnalysisCoordinator()
    
    return _ai_coordinator


async def demo_ai_coordinator():
    """Demo the AI analysis coordinator."""
    print("ðŸ¤– AI Analysis Coordinator Demo")
    print("=" * 35)
    
    # Test with real coordinator
    coordinator = get_ai_coordinator()
    
    test_code = """
def process_user_data(user_data):
    if not user_data.get('email'):
        raise ValueError('Email required')
    return {'id': user_data['id'], 'email': user_data['email']}
"""
    
    # Test classification
    categories = ['getter', 'setter', 'business_logic', 'validation', 'constructor']
    classification = await coordinator.classify_function(test_code, categories)
    
    print(f"Classification: {classification.result}")
    print(f"Confidence: {classification.confidence:.2f}")
    print(f"Reasoning: {classification.reasoning}")
    
    # Test intent analysis
    intent = await coordinator.analyze_intent(test_code)
    
    print(f"\nIntent Analysis:")
    print(f"Purpose: {intent.result['purpose']}")
    print(f"Functionality: {intent.result['functionality']}")
    print(f"Confidence: {intent.confidence:.2f}")


if __name__ == "__main__":
    asyncio.run(demo_ai_coordinator())